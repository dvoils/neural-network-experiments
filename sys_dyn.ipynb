{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNx5OWVklwQu3Co+V+iefdl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dvoils/neural-network-experiments/blob/main/sys_dyn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Associative Memory and Hopfield Networks\n",
        "\n",
        "* Hopfield, 1982. Neural networks and physical systems with emergent collective computational abilities\n",
        "* Amit et al. (1985)**: Introduced statistical mechanics tools like spin-glass theory to estimate storage limits (\\~0.138N for N neurons).\n",
        "\n",
        "**Key Concepts**:\n",
        "\n",
        "* Energy minimization and convergence dynamics are inherently **dynamical system properties**—the network evolves toward fixed points.\n",
        "* State space trajectories\n",
        "* Attractors vs. spurious states\n",
        "* Capacity vs. generalization\n",
        "\n",
        "## 2. Oscillatory Neural Networks (ONNs) as Generalized Attractor Systems\n",
        "\n",
        "* **Porod et al. (2023)** train oscillator states using **backpropagation through time**—a nontrivial dynamical approach.\n",
        "\n",
        "### Concepts\n",
        "\n",
        "* Local or global synchronization defines associative recall.\n",
        "* Unlike Hopfield nets (binary or continuous states), ONNs use **phase, amplitude, or frequency** as state variables.\n",
        "* Oscillators define richer dynamics (limit cycles, phase locking, chaos).\n",
        "* Attractor becomes not a point but a **trajectory** or **phase-locked manifold**.\n",
        "* More expressive “memory” than point attractors.\n",
        "\n",
        "\n",
        "## 3. CNNs and OCNNs (Roska & Chua) as Dynamical Substrates\n",
        "\n",
        "* **CNN Universal Machine**: A 2D grid of locally coupled cells (like pixels), governed by ODEs.\n",
        "\n",
        "### Concepts\n",
        "* Each cell is a dynamical system with neighbors affecting it, enabling fast, parallel processing.\n",
        "* Oscillatory modes allow encoding time-varying phenomena.\n",
        "\n",
        "### Applications\n",
        "\n",
        "* Image processing (edge detection, motion tracking)\n",
        "* Analog/digital hybrid computation\n",
        "* Field-programmable analog arrays (FPAAs)\n",
        "\n",
        "## 4. FPGA Implementations and Resource-Aware Architectures\n",
        "\n",
        "* **Szalkai & Porod** and **Ohi et al. (2023)** show ONNs achieving Hopfield-like associative memory with fewer resources.\n",
        "\n",
        "### Concepts\n",
        "* Hebbian vs. Storkey rules tested.\n",
        "* Implementation challenges: clock precision, jitter, quantization of phase/amplitude.\n",
        "\n",
        "\n",
        "## 5. Dynamical Systems View: Fixed Points, Limit Cycles, and Chaos\n",
        "\n",
        "* Hopfield → fixed point attractors.\n",
        "* ONNs → phase synchrony or limit cycle locking.\n",
        "* Hopf oscillators (Wang et al., 2024) bring bifurcation theory directly into network dynamics.\n",
        "* Dynamics of learning: Stability, bifurcations, training through dynamical transitions.\n",
        "\n"
      ],
      "metadata": {
        "id": "MPXAqiD41zG_"
      }
    }
  ]
}